{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet_L_One_class.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"BF78c6AeFCBO","colab_type":"code","outputId":"2540763f-487c-4fbb-b2ae-1db78102abd1","executionInfo":{"status":"ok","timestamp":1541847659163,"user_tz":-180,"elapsed":26139,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"JCWJZ_5vF0O2","colab_type":"code","outputId":"a7f1fb56-0934-430e-f36d-03c7c132fcab","executionInfo":{"status":"ok","timestamp":1541847661972,"user_tz":-180,"elapsed":2757,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","#from tensorflow import divide, multiply\n","from keras.layers import multiply\n","from keras import backend as K\n","\n","def unet():\n","    inputs = Input((256,256,1), name='input')\n","    #fixed_input = K.constant([1/255], float)\n","    #inputs = multiply([inputs, fixed_input])\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)    \n","    drop3 = Dropout(0.5)(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(drop3)\n","\n","    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge7 = concatenate([drop3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)    \n","    output = Conv2D(1, 1, activation = 'sigmoid', name='output')(conv9)\n","    \n","    #fixed_input = tf.constant([255], float)\n","    #output = multiply([output, fixed_input])\n","    model = Model(input = inputs, output = output)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"_lJKnGFfFMS_","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import cv2\n","from os import listdir, makedirs\n","from os.path import isfile, join, exists\n","\n","Path = '/content/gdrive/My Drive/Colab/Nails/data'\n","PathTrain = join(Path, 'train_two_classes')\n","\n","def adjustData(img,mask):\n","    if(np.max(img) > 1):\n","        img = img / 255\n","        #mask = np.delete(mask, np.s_[1], axis=3)\n","        mask = mask / 255\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n","                    save_to_dir = None, target_size = (256,256), seed = 1):\n","\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        train_path,\n","        classes = [image_folder],\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        train_path,\n","        classes = mask_folder,\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask)\n","        yield (img,mask)\n","\n","def get_files(path):\n","  return list([f for f in listdir(path) if isfile(join(path, f))])\n","\n","def get_file_data(path, file_name, target_size = (256,256)):\n","  img = cv2.imread(join(path, file_name), cv2.IMREAD_GRAYSCALE)\n","  img = img / 255\n","  img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n","  img = np.reshape(img, (1,) + img.shape + (1,))\n","  return img\n","\n","def resize_coordinates(coordinates,old_size,new_size):\n","  if len(coordinates) == 0:\n","    return coordinates\n","  coordinates[:,0] = coordinates[:,0] * (new_size[1]/old_size[1])\n","  coordinates[:,1] = coordinates[:,1] * (new_size[0]/old_size[0])\n","  return coordinates\n","\n","def find_centers(mask, minimal_size_prsent = 1):\n","  contours=find_contours(mask)\n","  minimal_size = mask.shape[0] * mask.shape[1] * (minimal_size_prsent/100)\n","  return find_centers_by_contours(contours, minimal_size)\n","\n","def find_contours(mask):\n","  m1 = mask.astype(np.uint8).copy()\n","  im2, contours, hierarchy = cv2.findContours(m1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","  return contours\n","  \n","def find_centers_by_contours(contours, minimal_size):\n","  centers = []\n","  areas = []\n","  cont = []\n","  for cnt in contours:\n","    M = cv2.moments(cnt)\n","    if M[\"m00\"] != 0:      \n","      if M[\"m00\"] > minimal_size:\n","        areas.append(M[\"m00\"])\n","        cont.append(np.array(cnt))\n","        cX = int(M[\"m10\"] / M[\"m00\"])\n","        cY = int(M[\"m01\"] / M[\"m00\"])\n","        centers.append([cX,cY])  \n","  return np.array(centers), np.array(areas), cont\n","\n","\n","def normalize(mask):\n","  mask = mask[0,:,:,:]\n","  mask = mask/mask.max()\n","  \n","  mask[mask > 0.5] = 1\n","  mask[mask <= 0.5] = 0\n","  mask=mask*255\n","  return mask\n","\n","def get_common_center(cnt, conturs):\n","  common_border = []\n","  for cc in conturs:\n","    mutch = False\n","    for p in cnt:\n","      for c in cc:\n","        if p[0][0] == c[0][0] and p[0][1] == c[0][1]:\n","          mutch = True\n","    if mutch:\n","      common_border.append(cc)\n","  \n","  centers0, areas0, cont0 = find_centers_by_contours(common_border, 0.05)\n","  if len(areas0) >0:\n","    i = np.argmax(areas0)\n","    return centers0[i]\n","  else:\n","    return []\n","\n","def get_data(mask):\n","  cont0 = find_contours(mask[:,:,0])\n","  centers1, areas1, cont1 = find_centers(mask[:,:,1], 0.3)\n","  centers_new = []\n","  for cont in cont1:\n","      common_center = get_common_center(cont, cont0)\n","      centers_new.append(common_center)\n","  \n","  return list(zip(centers1, centers_new))\n","\n","  \n","def saveResult(npMask, save_path, fileName, original_path, train_path = ''):\n","  if not exists(join(PathTrain, save_path)):\n","    makedirs(join(PathTrain, save_path))\n","  mask = normalize(npMask)\n","  \n","  img_original = cv2.imread(join(original_path, fileName))\n","  mask = cv2.resize(mask, (img_original.shape[1], img_original.shape[0])).astype(int)\n","  \n","  centers = []#get_data(mask)\n","  \n","  img_original[:,:,0] = (img_original[:,:,0] / (1 + (mask / 192))).astype(int)\n","  img_original[:,:,1] = (img_original[:,:,1] / (1 + (mask / 192))).astype(int)\n","\n","  for c in centers:\n","    cv2.circle(img_original, tuple(c[0]), 3, (255, 0, 0))\n","    if len(c[1])>0:\n","      cv2.circle(img_original, tuple(c[1]), 3, (255, 255, 255))\n","      cv2.circle(img_original, tuple(c[1]), 4, (0, 0, 0))\n","      cv2.line(img_original,tuple(c[0]),tuple(c[1]),(255,255,255),2)\n","  \n","  if train_path != '':\n","    train_files = [f for f in listdir(train_path) if isfile(join(train_path, f))]\n","    if fileName in train_files:\n","      cv2.putText(img_original,'train',(20,20),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n","  cv2.imwrite(join(join(PathTrain, save_path),fileName),img_original)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M-AAzoCaKMu5","colab_type":"code","colab":{}},"cell_type":"code","source":["def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n","    \"\"\"\n","    Freezes the state of a session into a pruned computation graph.\n","\n","    Creates a new computation graph where variable nodes are replaced by\n","    constants taking their current value in the session. The new graph will be\n","    pruned so subgraphs that are not necessary to compute the requested\n","    outputs are removed.\n","    @param session The TensorFlow session to be frozen.\n","    @param keep_var_names A list of variable names that should not be frozen,\n","                          or None to freeze all the variables in the graph.\n","    @param output_names Names of the relevant graph outputs.\n","    @param clear_devices Remove the device directives from the graph for better portability.\n","    @return The frozen graph definition.\n","    \"\"\"\n","    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n","    graph = session.graph\n","    with graph.as_default():\n","        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n","        output_names = output_names or []\n","        output_names += [v.op.name for v in tf.global_variables()]\n","        input_graph_def = graph.as_graph_def()\n","        if clear_devices:\n","            for node in input_graph_def.node:\n","                node.device = \"\"\n","        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n","                                                      output_names, freeze_var_names)\n","        return frozen_graph"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GsTwVUtbHpKN","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import backend as K\n","\n","def save_to_pb(model, file_name):\n","  frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\n","  tf.train.write_graph(frozen_graph, PathTrain, file_name + '.pb', as_text=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dO3GXozoFgb2","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","from keras.backend import clear_session\n","def train(checkpoint_to_save, steps_per_epoch, epochs, checkpoint_to_load = ''):\n","  clear_session()\n","  data_gen_args = dict(rotation_range=180,\n","                      width_shift_range=0.5,\n","                      height_shift_range=0.5,\n","                      shear_range=0.5,\n","                      zoom_range=0.5,\n","                      horizontal_flip=True,\n","                      fill_mode='nearest')\n","\n","  myGene = trainGenerator(10, PathTrain, 'pics', ['masks1'], data_gen_args)\n","  model = unet()\n","  if checkpoint_to_load != '':\n","    model.load_weights(join(PathTrain, checkpoint_to_load + '.hdf5'))\n","  model_checkpoint = ModelCheckpoint(join(PathTrain, checkpoint_to_save + '.hdf5'), monitor='loss',verbose=1, save_best_only=True)\n","  model.fit_generator(myGene,steps_per_epoch,epochs,callbacks=[model_checkpoint])\n","  save_to_pb(model, checkpoint_to_save)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NKhPa3BY1PbG","colab_type":"code","colab":{}},"cell_type":"code","source":["from datetime import datetime\n","def test(checkpoint, results_path):\n","  file_names = get_files(Path + '/test')\n","  model = unet()\n","  model.load_weights(join(PathTrain, checkpoint + '.hdf5'))  \n","  for file_name in file_names:\n","    x = get_file_data(Path + '/test', file_name)\n","    t1 = datetime.now()\n","    result = model.predict(x, verbose=0)\n","    t2 = datetime.now()\n","    saveResult(result, results_path, file_name, Path + '/test', PathTrain + '/pics')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tTrvJ0EW3ahL","colab_type":"code","outputId":"b23fb4c9-f7a9-4e4b-d5cf-7fd31557f52c","executionInfo":{"status":"ok","timestamp":1541847832252,"user_tz":-180,"elapsed":164518,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#train('test', 10, 1)\n","test('test', 'test_test')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"],"name":"stderr"}]},{"metadata":{"id":"egkyHGqU-4qK","colab_type":"code","outputId":"4ee68105-8f4d-42de-9fc9-aa6c25443e6b","executionInfo":{"status":"error","timestamp":1541363581002,"user_tz":-180,"elapsed":3848266,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"cell_type":"code","source":["for i in range(500):\n","  print('step ' + str(i))\n","  train('test', 200, 1, 'test')\n","  #test('test', 'test_test')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["step 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","Found 32 images belonging to 1 classes.\n","Found 32 images belonging to 1 classes.\n","200/200 [==============================] - 236s 1s/step - loss: 0.0156 - acc: 0.9943\n","\n","Epoch 00001: loss improved from inf to 0.01633, saving model to /content/gdrive/My Drive/Colab/Nails/data/train_two_classes/test.hdf5\n","INFO:tensorflow:Froze 157 variables.\n","INFO:tensorflow:Converted 157 variables to const ops.\n","step 1\n","Epoch 1/1\n","Found 32 images belonging to 1 classes.\n","Found 32 images belonging to 1 classes.\n","200/200 [==============================] - 205s 1s/step - loss: 0.0058 - acc: 0.9977\n","\n","Epoch 00001: loss improved from inf to 0.00616, saving model to /content/gdrive/My Drive/Colab/Nails/data/train_two_classes/test.hdf5\n","INFO:tensorflow:Froze 157 variables.\n","INFO:tensorflow:Converted 157 variables to const ops.\n","step 2\n","Epoch 1/1\n","Found 32 images belonging to 1 classes.\n","Found 32 images belonging to 1 classes.\n","  5/200 [..............................] - ETA: 5:09 - loss: 0.0030 - acc: 0.9987"],"name":"stdout"}]}]}