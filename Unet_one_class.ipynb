{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet_one_class.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"BF78c6AeFCBO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ef529ca9-6f6f-4822-a57d-373beba95a1e","executionInfo":{"status":"ok","timestamp":1540472986921,"user_tz":-180,"elapsed":1420,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"JCWJZ_5vF0O2","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","\n","def unet(pretrained_weights = None,input_size = (256,256,1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_lJKnGFfFMS_","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import cv2\n","from os import listdir\n","from os.path import isfile, join\n","\n","Path = '/content/gdrive/My Drive/Colab/Nails/data'\n","PathTrain = join(Path, 'train_one_class')\n","\n","def adjustData(img,mask):\n","    if(np.max(img) > 1):\n","        img = img / 255\n","        mask = mask / 255\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\", image_save_prefix  = \"image\", mask_save_prefix  = \"mask\",\n","                    save_to_dir = None, target_size = (256,256), seed = 1):\n","    '''\n","    can generate image and mask at the same time\n","    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n","    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n","    '''\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        train_path,\n","        classes = [image_folder],\n","        class_mode = None,\n","        color_mode = image_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = image_save_prefix,\n","        seed = seed)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        train_path,\n","        classes = [mask_folder],\n","        class_mode = None,\n","        color_mode = mask_color_mode,\n","        target_size = target_size,\n","        batch_size = batch_size,\n","        save_to_dir = save_to_dir,\n","        save_prefix  = mask_save_prefix,\n","        seed = seed)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask)\n","        yield (img,mask)\n","\n","def testData(test_path, target_size = (256,256), flags = cv2.IMREAD_GRAYSCALE):\n","  onlyfiles = [f for f in listdir(test_path) if isfile(join(test_path, f))]\n","  result = []\n","  file_names = []\n","  for f in onlyfiles:\n","    file_names.append(f)\n","    img = cv2.imread(join(test_path, f), flags)\n","    img = img / 255\n","    img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n","    img = np.reshape(img, (1,) + img.shape + (1,))\n","    result.append(img)\n","  return result, file_names\n","\n","def saveResult(npMask, save_path, fileName, original_path, train_path = ''):\n","  if not os.path.exists(join(PathTrain, save_path)):\n","    os.makedirs(join(PathTrain, save_path))\n","  img = npMask[0,:,:,0]\n","  img_original = cv2.imread(join(original_path, fileName))\n","  img = cv2.resize(img, (img_original.shape[1], img_original.shape[0]))    \n","  img = (img*(256/img.max())).astype(int)  \n","  img_original[:,:,0] = (img_original[:,:,0]).astype(int)\n","  img_original[:,:,1] = (img_original[:,:,1] / (1 + (img / 192))).astype(int)\n","  img_original[:,:,2] = (img_original[:,:,2] / (1 + (img / 192))).astype(int)\n","  if train_path != '':\n","    train_files = [f for f in listdir(train_path) if isfile(join(train_path, f))]\n","    if fileName in train_files:\n","      cv2.putText(img_original,'train',(20,20),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n","  cv2.imwrite(join(join(PathTrain, save_path),fileName),img_original)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dO3GXozoFgb2","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","def train(checkpoint_to_save, steps_per_epoch, epochs, checkpoint_to_load = ''):\n","  data_gen_args = dict(rotation_range=0.6,\n","                      width_shift_range=0.1,\n","                      height_shift_range=0.1,\n","                      shear_range=0.1,\n","                      zoom_range=0.1,\n","                      horizontal_flip=True,\n","                      fill_mode='nearest')\n","  \n","  #image_color_mode: grayscale, rgb\n","  myGene = trainGenerator(1,PathTrain,'pics','masks',data_gen_args,save_to_dir = None,image_color_mode = 'grayscale')\n","  model = unet()\n","  if checkpoint_to_load != '':\n","    model.load_weights(join(PathTrain, checkpoint_to_save))\n","  model_checkpoint = ModelCheckpoint(join(PathTrain, checkpoint_to_save), monitor='loss',verbose=1, save_best_only=True)\n","  model.fit_generator(myGene,steps_per_epoch,epochs,callbacks=[model_checkpoint])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NKhPa3BY1PbG","colab_type":"code","colab":{}},"cell_type":"code","source":["def test(checkpoint, results_path):\n","  #flags: IMREAD_COLOR, IMREAD_GRAYSCALE\n","  X, file_names = testData(Path + '/test', flags = cv2.IMREAD_GRAYSCALE )\n","  model = unet()\n","  model.load_weights(join(PathTrain, checkpoint))\n","  for fileName, x in zip(file_names, X):\n","      result = model.predict(x, verbose=0)\n","      saveResult(result, results_path, fileName, Path + '/test', PathTrain + '/pics')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tTrvJ0EW3ahL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"de6f501b-f2df-41ff-9c81-4cec5509fca4","executionInfo":{"status":"ok","timestamp":1540473019220,"user_tz":-180,"elapsed":26048,"user":{"displayName":"Victor Papenko","photoUrl":"https://lh5.googleusercontent.com/-Ee8exR9jNvI/AAAAAAAAAAI/AAAAAAAAAAA/wyqS7osC7SE/s64/photo.jpg","userId":"07873734355624814085"}}},"cell_type":"code","source":["#train('unet_membrane.hdf5', 100, 1)\n","test('unet_membrane.hdf5', 'test_results_one_class')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"],"name":"stderr"}]},{"metadata":{"id":"egkyHGqU-4qK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"f082e7f3-57b7-4a1b-ca97-b46b503bb8e9"},"cell_type":"code","source":["for i in range(100):\n","  print('step ' + str(i))\n","  train('unet_membrane.hdf5', 1000, 1, 'unet_membrane.hdf5')\n","  test('unet_membrane.hdf5', 'test_results_one_class')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["step 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","Found 10 images belonging to 1 classes.\n","Found 10 images belonging to 1 classes.\n","  85/1000 [=>............................] - ETA: 5:08 - loss: 6.0252e-04 - acc: 0.9998"],"name":"stdout"}]}]}